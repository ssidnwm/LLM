{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 및 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전본\n",
    "\n",
    "## 수정본\n",
    "\n",
    "# 데이터 경로\n",
    "data_path=r'G:\\내 드라이브\\LAB_works\\법률 LLM 프로젝트\\data\\데이터 전처리\\3. JSON 컨버팅\\JSON byChapter\\R078r3e_fullChapter_converted_ver1.json'\n",
    "\n",
    "# 텍스트 추출\n",
    "with open(data_path, 'rb') as source:\n",
    "    dict_originJSON = json.load(source)\n",
    "\n",
    "#print(''.join(lines))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 수정본\n",
    "\n",
    "# 데이터 경로\n",
    "data_path=r'G:\\내 드라이브\\LAB_works\\법률 LLM 프로젝트\\data\\데이터 전처리\\2. 가공 텍스트\\R078r3am1e_processed.txt'\n",
    "\n",
    "# 텍스트 추출\n",
    "with open(data_path, 'rb') as source:\n",
    "    lines_amendment = source.readlines()\n",
    "    lines_amendment = [element.decode('utf-8') for element in lines_amendment]\n",
    "\n",
    "#print(''.join(lines))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전역 변수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_main_title = (\"main\", r'\\s*\\d{1,}\\.\\s+')\n",
    "pattern_article = (\"art\", r'\\s*(\\d{1,}\\.){2}\\s+')\n",
    "pattern_paragraph = (\"para\", r'\\s*(\\d{1,}\\.){3}\\s+')\n",
    "pattern_sub_paragraph = (\"paraS\", r'\\s*(\\d{1,}\\.){4}\\s+')\n",
    "pattern_item = (\"item\", r'\\s*\\([a-hj-u]\\)\\s+')\n",
    "pattern_sub_item = (\"itemS\", r'\\s*\\([ivx]{1,}\\)\\s+')\n",
    "pattern_description = (\"dsc\", r'\\s*[A-Z]') # 추후에 수정이 필요할 수 있음\n",
    "\n",
    "patternL = [pattern_main_title, pattern_article, pattern_paragraph, pattern_sub_paragraph, pattern_item, pattern_sub_item, pattern_description]\n",
    "patternL_stage = [pattern_main_title, pattern_article, pattern_paragraph, pattern_sub_paragraph]\n",
    "\n",
    "dict_tagName = {\"item\":\"Item\", \"itemS\":\"Sub-item\", \"dsc\":\"Description\",\n",
    "                \"main\":\"Chapter main title\",\n",
    "                \"art\":\"Article\", \"para\":\"Paragraph\", \"paraS\":\"Sub-paragraph\"}\n",
    "\n",
    "tags_stage = [\"main\", \"art\", \"para\", \"paraS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테그 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineTagger(linesL_input, flag_return_onlyTag=True):\n",
    "    \n",
    "    ## 전역 변수 로딩\n",
    "    global patternL\n",
    "    \n",
    "    ## 행 별로 패턴 일치 여부 검색 및 결과 테깅\n",
    "    tupleL_tagInfo = []\n",
    "    for tag, pattern in patternL:\n",
    "        pattern = r\"^\" + fr\"{pattern}\"\n",
    "        tupleL_tagInfo.append([(index, tag) for index, line in enumerate(linesL_input) if re.match(pattern, line)])\n",
    "    \n",
    "    ## 리스트 평탄화 및 오름차순 정렬\n",
    "    tupleL_tagInfo = sum(tupleL_tagInfo,[])\n",
    "    tupleL_tagInfo.sort()\n",
    "    \n",
    "    ## 예외처리 (조건 중복, item의 알파뱃 i ~ sub item의 로마자 i)\n",
    "    pattern_ish = r'^\\s*\\(h\\)\\s'\n",
    "    pattern_isi = r'^\\s*\\(i\\)\\s'\n",
    "    pattern_isii = r'^\\s*\\(ii\\)\\s'\n",
    "\n",
    "    #/ Check point 1: item (h)가 존재하는가? (문제가 될 수 있는 item (i)의 선행 조건)\n",
    "    #/ True: check point 2 확인\n",
    "    idxL_ish = [index for index, line in enumerate(linesL_input) if re.match(pattern_ish, line)]\n",
    "    for idx_ish in idxL_ish:\n",
    "   \n",
    "        #// Check point 2: item (h)의 sub item이 존재하는가? (tagInfo만으로는 구분할 수 없는 요소) + 문단 종료에 따른 인덱싱 오류에 대해 대비할 필요가 있음\n",
    "        #// True: check point 3-1 확인\n",
    "        if re.match(pattern_isii, linesL_input[idx_ish+2]):\n",
    "            idx_cursor = idx_ish + 3\n",
    "            while (tupleL_tagInfo[idx_cursor][1]==\"itemS\"):\n",
    "                idx_cursor += 1\n",
    "            #/// Check point 3: 마지막 itemS로 테그된 행이 item (i)일 수도 있지 않은가?\n",
    "            #/// True: 테그 변환    \n",
    "            if re.match(pattern_isi, linesL_input[idx_cursor-1]):\n",
    "                tupleL_tagInfo[idx_cursor-1] = (idx_cursor-1, \"item\")\n",
    "   \n",
    "    #// False: check point 3-2 확인\n",
    "        else:\n",
    "            idx_cursor = idx_ish + 1\n",
    "            #/// Check point 3: item (h) 다음으로 itemS로 테그된 행이 item (i)이 존재하는가?\n",
    "            #// True: 테그 변환\n",
    "            if tupleL_tagInfo[idx_cursor][1]==\"itemS\":\n",
    "                tupleL_tagInfo[idx_cursor] = (idx_cursor, \"item\")\n",
    "    \n",
    "    ## 결과 반환\n",
    "    if flag_return_onlyTag:\n",
    "        return([tag for idx, tag in tupleL_tagInfo])      \n",
    "    else:\n",
    "        return(tupleL_tagInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱스 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxFinder(tags, idx_start, tag_target, tag_end=False):\n",
    "    global tags_stage\n",
    "    \n",
    "    idxL_target = []\n",
    "    idx_cursor = idx_start\n",
    "    idx_end = len(tags) - 1\n",
    "    #tags_out = tags_stage.copy().split()\n",
    "\n",
    "    \n",
    "    if tag_end:\n",
    "        while (idx_cursor <= idx_end and tags[idx_cursor] not in tag_end):\n",
    "            if tags[idx_cursor]==tag_target:\n",
    "                idxL_target.append(idx_cursor)\n",
    "            idx_cursor += 1\n",
    "    \n",
    "    else:\n",
    "        while (idx_cursor <= idx_end):\n",
    "            if tags[idx_cursor]==tag_target:\n",
    "                idxL_target.append(idx_cursor)\n",
    "            idx_cursor += 1\n",
    "            \n",
    "    return(idxL_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 페턴 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patternFinder(target_tag, base_patternL):\n",
    "    base_patternD = dict(base_patternL)\n",
    "    target_pattern = base_patternD[target_tag]\n",
    "    \n",
    "    return(target_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력 페턴을 바탕으로 문장 분해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineParser(line, break_pattern, sel_group, opt_strip=False):\n",
    "    breaks = re.search(break_pattern, line)\n",
    "    \n",
    "    parsed_result = []   \n",
    "    for idx in sel_group:\n",
    "        if opt_strip:\n",
    "            parsed_result.append(breaks.group(idx).strip())\n",
    "        else:\n",
    "            parsed_result.append(breaks.group(idx))\n",
    "            \n",
    "    return(parsed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문항 번호에서 주소 정보 구체화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Example usage\\nsentences = [\\n    \"5.13.4.3 This particle should be (...)\",\\n    \"7.21 This is another example (...)\",\\n    \"8.9.2 Here is yet another example (...)\"\\n]\\n\\nfor sentence in sentences:\\n    parsed_info = parse_structure(sentence)\\n    if parsed_info:\\n        print(parsed_info)\\n    else:\\n        print(f\"Could not parse: {sentence}\")\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addressParser(address):\n",
    "    # Define the regex pattern\n",
    "    pattern = r'(\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))?(?:\\.(\\d+))?.*'\n",
    "    \n",
    "    # Match the pattern to the sentence\n",
    "    match = re.match(pattern, address)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the matched groups\n",
    "        chapter = match.group(1)\n",
    "        article = match.group(2)\n",
    "        paragraph = match.group(3)\n",
    "        sub_paragraph = match.group(4)\n",
    "        \n",
    "        # Create the result dictionary\n",
    "        result = {\n",
    "            'Chapter': chapter,\n",
    "            'Article': article,\n",
    "            'Paragraph': paragraph,\n",
    "            'Sub-paragraph': sub_paragraph,\n",
    "        }\n",
    "        \n",
    "        # Filter out None values\n",
    "        result = {k: v for k, v in result.items() if v is not None}\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ## Example usage ##\n",
    "\n",
    "sentences = [\n",
    "    \"5.13.4.3 This particle should be (...)\",\n",
    "    \"7.21 This is another example (...)\",\n",
    "    \"8.9.2 Here is yet another example (...)\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    parsed_info = parse_structure(sentence)\n",
    "    if parsed_info:\n",
    "        print(parsed_info)\n",
    "    else:\n",
    "        print(f\"Could not parse: {sentence}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON 구성 요소 생성 및 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 독립형 sublistLoader (미사용)\n",
    "\n",
    "def sublistLoader(lines, tags, base_dict, target_tag, pivot_idx, opt_parse=False, opt_strip=False):\n",
    "    global patterL\n",
    "    global dict_tagName\n",
    "    global tags_stage\n",
    "\n",
    "    tag_pivot = tags[pivot_idx]\n",
    "    tags_end = tags_stage.copy()\n",
    "    tags_end.append(tag_pivot)\n",
    "\n",
    "    idxL_loader = idxFinder(tags, pivot_idx+1, target_tag, tag_end=tags_end)\n",
    "    ##        \n",
    "    lines_loader = []\n",
    "    for idx_loader in idxL_loader:\n",
    "        lines_loader.append(lines[idx_loader].strip())\n",
    "\n",
    "    ##\n",
    "    if len(lines_loader):\n",
    "        if opt_parse:\n",
    "            pattern_pivot = patternFinder(tag_pivot, patterL)\n",
    "            ele_searchingKey = lineParser(lines[pivot_idx], rf\"({pattern_pivot})\" + r\"(.*)\", sel_group=[3], opt_strip=opt_strip)[0]\n",
    "        else:\n",
    "            ele_searchingKey = lines[pivot_idx].strip()\n",
    "            \n",
    "        idx_pivotInlist = base_dict[fullName_pivot].index(ele_searchingKey)\n",
    "\n",
    "        fullName_pivot = dict_tagName[tag_pivot]\n",
    "        base_dict[fullName_pivot][idx_pivotInlist].append(lines_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listLoader(lines, tags, base_dict, target_tag, pivot_idx, target_tag_subList=None):\n",
    "    global dict_tagName\n",
    "    global tags_stage\n",
    "    \n",
    "    idxL_loader = idxFinder(tags, pivot_idx+1, target_tag, tag_end=tags_stage)\n",
    "    if target_tag_subList:\n",
    "        idx_end = len(lines)-1\n",
    "        idxL_with_subList = [idx_loader for idx_loader in idxL_loader if idx_loader < idx_end and tags[idx_loader+1]==target_tag_subList]\n",
    "    ##        \n",
    "    lines_loader = []\n",
    "    for idx_loader in idxL_loader:\n",
    "        if target_tag_subList and idx_loader in idxL_with_subList:\n",
    "            lines_subLoader = []\n",
    "            idxL_subLoader = idxFinder(tags, idx_loader+1, target_tag_subList, tag_end=target_tag)\n",
    "            for idx_subLoader in idxL_subLoader: lines_subLoader.append(lines[idx_subLoader].strip())\n",
    "            \n",
    "            lines_loader.append([lines[idx_loader].strip(), lines_subLoader])\n",
    "            \n",
    "        else:     \n",
    "            lines_loader.append(lines[idx_loader].strip())\n",
    "\n",
    "    ##\n",
    "    if len(lines_loader):\n",
    "        fullName = dict_tagName[target_tag]\n",
    "        base_dict[fullName] = lines_loader\n",
    "        \n",
    "## 재귀 함수를 이용한 구조로 변경할 수 있지 않을까? depth와 target tags를 이용한 확장성 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictLoader(lines, tags, base_dict, pivot_pattern, pivot_idx, opt_dsc=False, opt_item=False, opt_itemS=False):\n",
    "    \n",
    "    numbering, dsc_0 = lineParser(lines[pivot_idx], rf\"({pivot_pattern})\" + r\"(.*)\", sel_group=[1,3], opt_strip=True)\n",
    "    dict_loaded = base_dict[numbering] = {}\n",
    "    \n",
    "    if opt_dsc:\n",
    "        listLoader(lines, tags, dict_loaded, target_tag=\"dsc\", pivot_idx=pivot_idx)\n",
    "        if \"Description\" in list(dict_loaded.keys()): dict_loaded[\"Description\"].insert(0,dsc_0)\n",
    "        else: dict_loaded[\"Description\"] = [dsc_0]\n",
    "        \n",
    "    if opt_item:\n",
    "        if opt_itemS:\n",
    "            listLoader(lines, tags, dict_loaded, target_tag=\"item\", target_tag_subList=\"itemS\", pivot_idx=pivot_idx)\n",
    "        else:\n",
    "            listLoader(lines, tags, dict_loaded, target_tag=\"item\", pivot_idx=pivot_idx)\n",
    "        \n",
    "    return(dict_loaded)\n",
    "\n",
    "## dsc만 예외 처리로 남겨 두고 나머지는 구체적인 변수로 받아서 반복 처리 (sub list에 대해서는 [..., [...]] 같은 구조로 처리할 수 있을 듯하다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_dictLoader(lines, tags, base_dict, init_idx, parental_tag):\n",
    "    global patternL_stage\n",
    "    tags_stage = [tag for tag, pattern in patternL_stage]\n",
    "    \n",
    "    idxL_parentalTag = idxFinder(tags=tags, idx_start=init_idx, tag_target=parental_tag, tag_end=tags_stage[:tags_stage.index(parental_tag)])\n",
    "    pattern_parentalTag = patternFinder(parental_tag, patternL)\n",
    "    \n",
    "    for idx_parentalTag in idxL_parentalTag:\n",
    "        \n",
    "        dict_parental = dictLoader(lines, tags, base_dict, pattern_parentalTag, idx_parentalTag, opt_dsc=True, opt_item=True, opt_itemS=True)\n",
    "        \n",
    "        if parental_tag != tags_stage[-1]:\n",
    "            idx_parentalStage = tags_stage.index(parental_tag)\n",
    "            tag_child = tags_stage[idx_parentalStage+1]\n",
    "            recursive_dictLoader(lines, tags, dict_parental, idx_parentalTag+1, tag_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictInitiator_chapter(lines, tags, main_line_idx):\n",
    "    dict_return = {}\n",
    "    line_main = lines_chapter[main_line_idx]\n",
    "    num_chapter, title_chapter = [elm.strip() for elm in line_main.split('.')]\n",
    "    dict_return[\"Chapter\"] = num_chapter\n",
    "    dict_return[\"Title\"] = title_chapter\n",
    "    \n",
    "    listLoader(lines, tags, dict_return, target_tag=\"dsc\", pivot_idx=main_line_idx)\n",
    "    listLoader(lines, tags, dict_return, target_tag=\"item\", target_tag_subList=\"itemS\", pivot_idx=main_line_idx)\n",
    "    \n",
    "    return dict_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 워킹 스페이스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단락 구분 및 유형 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단락 구분\n",
    "\n",
    " ## 단락 시작 지점 확인\n",
    "patten_startSect = r\".*?\\bto read:\"\n",
    "idxs_startSect = [index for index, line in enumerate(lines) if re.match(patten_startSect, line)]\n",
    "\n",
    "idxs_endSect = idxs_startSect.copy()\n",
    "idxs_endSect.pop(0)\n",
    "idxs_endSect.append(len(lines))\n",
    "\n",
    " ## 단락 구분 및 개별 저장\n",
    "linesL_sect = []\n",
    "for idx_startSect, idx_endSect in zip(idxs_startSect, idxs_endSect):\n",
    "   lines_sect = lines[idx_startSect:idx_endSect]\n",
    "   linesL_sect.append(lines_sect)\n",
    "\n",
    " ## 유형 확인 후 dict 자료형으로 전환\n",
    "dictL_sect = []\n",
    "for lines_sect in linesL_sect:\n",
    "    line_startSect = lines_sect[0].lower()\n",
    "    flag_type = \"\"\n",
    "    \n",
    "    if \"amend\" in line_startSect:\n",
    "        flag_type = \"Amend\"\n",
    "       \n",
    "    elif \"insert\" in line_startSect:\n",
    "        flag_type = \"Insert\"\n",
    "        \n",
    "    elif \"renumber\" in line_startSect:\n",
    "        flag_type = \"Renumber\" \n",
    "        \n",
    "    dict_sect = {\"Type\":flag_type, \"Header\":lines_sect[0], \"Base\":lines_sect[1:], \"Tag\":lineTagger(lines_sect[1:])}\n",
    "    dictL_sect.append(dict_sect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_sect in dictL_sect:\n",
    "\n",
    "    tags_stage = [tag for tag, pattern in patternL_stage]\n",
    "    topStage = tags_stage[max(tags_stage.index(tag_inMainTarget) for tag_inMainTarget in dict_sect[\"Tag\"] if tag_inMainTarget in tags_stage)]\n",
    "\n",
    "    if topStage == \"main\":\n",
    "        dict_baseToJSON= dictInitiator_chapter(dict_sect['Base'], dict_sect['Tag'], main_line_idx=0)\n",
    "    else:\n",
    "        dict_baseToJSON = {}\n",
    "\n",
    "    #\n",
    "    recursive_dictLoader(dict_sect['Base'], dict_sect['Tag'], dict_baseToJSON, init_idx=0, parental_tag=topStage)\n",
    "\n",
    "    #\n",
    "    dict_sect['JSON'] = dict_baseToJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주소 특정 및 수정 사항 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_sect in dictL_sect:\n",
    "\n",
    "  for address_key in list(dict_sect[\"JSON\"].keys()):\n",
    "      \n",
    "      address_info = list[addressParser(address_key).values()]\n",
    "      address_depth = len(address_info)\n",
    "      \n",
    "      addressL = []\n",
    "      tmp = \"\"\n",
    "      for frag in address_info:\n",
    "        tmp = tmp + frag + \".\"\n",
    "        addressL.append(tmp)\n",
    "      \n",
    "      target_dict = dict_originJSON  \n",
    "      for address in addressL:\n",
    "        target_dict = target_dict[address]\n",
    "        \n",
    "      target_dict = dict_sect[\"JSON\"][address_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON 직렬화 처리 후 파일 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"R078r3e_fullchpter_converted_ver1.json\", \"w\") as file:\n",
    "    json.dump(dict_full, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개별 챕터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_chapter = list(filter(lambda x: \"chapter\" in x, list(dict_full.keys())))\n",
    "\n",
    "for number_of_chapter in range(len(linesL_chapter)):\n",
    "    with open(f\"R078r3e_chapter{number_of_chapter+1}_converted_ver1.json\", \"w\") as file:\n",
    "        json.dump(dict_full[keys_chapter[number_of_chapter]], file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
